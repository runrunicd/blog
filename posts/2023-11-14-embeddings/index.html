<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Embeddings Use Cases | Shel (Run) Zhou&#39;s Blog</title>
<meta name="keywords" content="large-language-model, embeddings">
<meta name="description" content="Introduction When I first heard about text embeddings, I was perplexed. My tech lead handed me an 800-page Natural Language Processing textbook, but I did not finish reading it. Now, with the capabilities of OpenAI models, it&rsquo;s time to learn and broadly leverage embeddings to accomplish many tasks that were hard be achieved by human labor or simple data analysis, thanks to easy access to these embeddings.
Let&rsquo;s start exploring:">
<meta name="author" content="Run Zhou">
<link rel="canonical" href="https://runrunicd.github.io/blog/posts/2023-11-14-embeddings/">
<link crossorigin="anonymous" href="/blog/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css" integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U&#43;6hYRq/Ez/nm5vg=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/blog/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://runrunicd.github.io/blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://runrunicd.github.io/blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://runrunicd.github.io/blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://runrunicd.github.io/blog/apple-touch-icon.png">
<link rel="mask-icon" href="https://runrunicd.github.io/blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Embeddings Use Cases" />
<meta property="og:description" content="Introduction When I first heard about text embeddings, I was perplexed. My tech lead handed me an 800-page Natural Language Processing textbook, but I did not finish reading it. Now, with the capabilities of OpenAI models, it&rsquo;s time to learn and broadly leverage embeddings to accomplish many tasks that were hard be achieved by human labor or simple data analysis, thanks to easy access to these embeddings.
Let&rsquo;s start exploring:" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://runrunicd.github.io/blog/posts/2023-11-14-embeddings/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-14T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-11-14T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Embeddings Use Cases"/>
<meta name="twitter:description" content="Introduction When I first heard about text embeddings, I was perplexed. My tech lead handed me an 800-page Natural Language Processing textbook, but I did not finish reading it. Now, with the capabilities of OpenAI models, it&rsquo;s time to learn and broadly leverage embeddings to accomplish many tasks that were hard be achieved by human labor or simple data analysis, thanks to easy access to these embeddings.
Let&rsquo;s start exploring:"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://runrunicd.github.io/blog/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Embeddings Use Cases",
      "item": "https://runrunicd.github.io/blog/posts/2023-11-14-embeddings/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Embeddings Use Cases",
  "name": "Embeddings Use Cases",
  "description": "Introduction When I first heard about text embeddings, I was perplexed. My tech lead handed me an 800-page Natural Language Processing textbook, but I did not finish reading it. Now, with the capabilities of OpenAI models, it\u0026rsquo;s time to learn and broadly leverage embeddings to accomplish many tasks that were hard be achieved by human labor or simple data analysis, thanks to easy access to these embeddings.\nLet\u0026rsquo;s start exploring:",
  "keywords": [
    "large-language-model", "embeddings"
  ],
  "articleBody": "Introduction When I first heard about text embeddings, I was perplexed. My tech lead handed me an 800-page Natural Language Processing textbook, but I did not finish reading it. Now, with the capabilities of OpenAI models, it’s time to learn and broadly leverage embeddings to accomplish many tasks that were hard be achieved by human labor or simple data analysis, thanks to easy access to these embeddings.\nLet’s start exploring:\nClustering Search Recommendations Classification Anomaly detection Goals The ultimate goal is to become familiar with the framework of leveraging embeddings to accomplish applicable tasks. The best way to learn and improvise is first by getting your hands dirty with the data and tools. Optimization and deep-diving happen later naturally.\nSummarize key terminology, concept, and usage of text embeddings Build the basic framework and standardized iPython notebooks for each use case that could benefit from text embeddings Brainstorm business use cases and ideas for improvements What do you need to know about embeddings? An embedding is a vector (list) of floating point numbers, representing a text string. The distance between two embeddings (vectors) measures their relatedness. The smaller the distance, the higher they are related, vice versa. Dimensionality reduction methods: t-SNE, a non-linear dimension reduction method, which stands for t-distributed Stochastic Neighbor Embedding. The ML algorithm calculates the similarity in both high dimensional sapce and low dimensional space, then the similarity difference in both spaces is minimized using an optimization method, for instance, gradient descend. It was developed by Laurens van der Maaten and Geoffrey Hinton in 2008. Here’s a brief overview of what t-SNE does and how it work. PCA, a linear dimension reduction method, where the data in high dimensional space is mapped linearly into low dimensional space while maximizing the variance of the data. Use Cases Clustering Can we identify clusters among movie reviews and their themes? It’s going to be difficult to review through all reviews and identify clusters of movie reviews. With AI, we can achieve that and I’ll demo it here. Let’s use Rotten Tomatoes dataset. To obtain text embeddings, let’s use OpenAI’s embeddings API and the model text-embedding-ada-002 is recommended. Note: all the code and data are open to public.\n# Ensure you have your API key set in your environment per the README: https://github.com/openai/openai-python#usage import openai openai.api_key = '[openai_key]' import pandas as pd import numpy as np import tiktoken import sys from typing import List, Optional from sklearn.manifold import TSNE from ast import literal_eval # Now try to import your module again def get_embedding(text: str, engine=\"text-similarity-davinci-001\", **kwargs) -\u003e List[float]: # replace newlines, which can negatively affect performance. text = text.replace(\"\\n\", \" \") return openai.Embedding.create(input=[text], engine=engine, **kwargs)[\"data\"][0][\"embedding\"] # Embedding model parameters embedding_model = \"text-embedding-ada-002\" embedding_encoding = \"cl100k_base\" # this the encoding for text-embedding-ada-002 max_tokens = 8000 # the maximum for text-embedding-ada-002 is 8191 from datasets import load_dataset dataset = load_dataset(\"rotten_tomatoes\") df = dataset['train'].to_pandas() print(\"{x} rows in df.\".format(x=len(df))) This is the sample data. The label is either 1 for positive sentiment or 0 for negative sentiment for the movie reviews.\ntext label the rock is destined to be the 21st century’s … 1 the gorgeously elaborate continuation of \" the… 1 Here, we get embeddings for the top 5000 move reviews.\ntop_n = 5000 encoding = tiktoken.get_encoding(embedding_encoding) # omit reviews that are too long to embed df[\"n_tokens\"] = df['text'].apply(lambda x: len(encoding.encode(x))) df = df[df.n_tokens \u003c= max_tokens].tail(top_n) # get embeddings and save them df[\"embedding\"] = df['text'].apply(lambda x: get_embedding(x, engine=embedding_model)) df.to_csv(\"./rotten_tomatoes_with_embeddings_{x}.csv\".format(x=top_n)) Apply Kmeans algorithm to the embeddings to identify clusters.\nimport numpy as np from sklearn.cluster import KMeans # Convert to a list of lists of floats matrix = np.vstack(df.embedding.apply(literal_eval).to_list()) n_clusters = 5 kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42) kmeans.fit(matrix) df['cluster'] = kmeans.labels_ df.groupby(\"cluster\").label.mean().sort_values() We can see that the mean of label values varies by cluster, suggesting that the sentiments are separated by the clustering, espectially cluster (2), cluster (1, 0, 4), and cluster (3).\nCluster Mean 2 0.010241 1 0.091311 0 0.099548 4 0.113420 3 0.480874 To visualize the clusters, transform the embeddings of high-dimension 1536 to 2D by t-SNE.\nfrom sklearn.manifold import TSNE import matplotlib import matplotlib.pyplot as plt import plotly.express as px tsne = TSNE(n_components=2, perplexity=15, random_state=42, init=\"random\", learning_rate=200) vis_dims2 = tsne.fit_transform(matrix) # Define the color map for the clusters color_map = { 0: 'firebrick', # Cluster 0 1: 'orangered', # Cluster 1 2: 'gold', # Cluster 2 3: 'limegreen', # Cluster 3 4: 'maroon' # Cluster 4 } # Map the cluster labels to colors df['color'] = df['cluster'].map(color_map) # Convert cluster to a categorical type with the specified order df['cluster'] = pd.Categorical(df['cluster'], categories=[0, 1, 2, 3, 4], ordered=True) # Create a DataFrame from the t-SNE results df_tsne = pd.DataFrame({'Dimension 1': vis_dims2[:, 0], 'Dimension 2': vis_dims2[:, 1], 'Cluster': df['cluster'], 'Color': df['color']}) # Create the 2D scatter plot using Plotly Express fig = px.scatter( df_tsne, x='Dimension 1', y='Dimension 2', color='Cluster', labels={'Cluster': 'Cluster'}, title='Clusters identified visualized in 2D using t-SNE', color_discrete_map=color_map # Apply the color map ) # Define the category orders for the legend to make it discrete fig.update_traces(marker=dict(size=3), selector=dict(mode='markers')) # Adjust marker size fig.update_layout( legend=dict( traceorder='normal', title_text='Cluster', title_font=dict(size=14) ) ) # Show the plot fig.show() 2D visualization from t-SNE We can identify the clusters by the differently colored dense cores.\n2D visualization from PCA It’s exploratory, so it’s worthwhile to see PCA 2D results too. We label positive reviews green and negative red. 3D visualization from t-SNE Sometimes, it’s helpful to identify clusters in 3D visualization as there might be more than two major forces critical in classifying the move reviews. You may wonder why are the movie reviews in each cluster grouped together? When we go on to the next section, we may see that the green cluster is for positive reviews and the other four are quite negative. Cluster theme Furthermore, we can leverage the model text-davinci-003 to summarize the theme for each cluster of movie reviews on Rotten Tomatoes.\nLet’s summarize the clusters, the mean sentiment, and the theme. Cluster 2 is very negative, expressing disappointment with the movies. In contrast, cluster 3 is very positive, with praise. Finally, clusters 1, 0, and 4 are closer to negative reviews but are not as disappointed as cluster 2.\nCluster Mean Sentiment Theme 2 0.010241 Disappointed with the quality of the movie. 1 0.091311 The reviews are all negative and critical of the movie. 0 0.099548 All of the reviews are negative and express dissatisfaction with the product or experience. 4 0.113420 Disappointment with the quality of the product or experience. 3 0.480874 All of the reviews are positive and praise the movie for its unique qualities, such as its surreal sense of humor, technological finish, insightful writing, delicate performances, and character-driven storytelling. Cluster 0 Theme: All of the reviews are negative and express dissatisfaction with the product or experience. 1, now as a former gong show addict , i'll admit it , my only complaint i 0, there's just no currency in deriding james bond for being a clichéd , 0, ecks this one off your must-see list . 0, skip this turd and pick your nose instead because you're sure to get m 0, this movie is about the worst thing chan has done in the united states ---------------------------------------------------------------------------------------------------- Cluster 1 Theme: The reviews are all negative and critical of the movie. 0, the type of dumbed-down exercise in stereotypes that gives the [teen c 0, just not campy enough 0, not so much farcical as sour . 0, a one-trick pony whose few t\u0026a bits still can't save itself from being 0, cuba gooding jr . valiantly mugs his way through snow dogs , but even ---------------------------------------------------------------------------------------------------- Cluster 2 Theme: Disappointed with the quality of the movie. 0, its generic villains lack any intrigue ( other than their funny accent 0, one of the most highly-praised disappointments i've had the misfortune 0, . . . with the candy-like taste of it fading faster than 25-cent bubbl 0, for all its impressive craftsmanship , and despite an overbearing seri 0, the script by vincent r . nebrida . . . tries to cram too many ingredi ---------------------------------------------------------------------------------------------------- Cluster 3 Theme: All of the reviews are positive and praise the movie for its unique qualities, such as its surreal sense of humor, technological finish, insightful writing, delicate performances, and character-driven storytelling. 1, what elevates the movie above the run-of-the-mill singles blender is i 0, at least it's a fairly impressive debut from the director , charles st 1, insightfully written , delicately performed 1, one of those exceedingly rare films in which the talk alone is enough 1, a stylish but steady , and ultimately very satisfying , piece of chara ---------------------------------------------------------------------------------------------------- Cluster 4 Theme: Disappointment with the quality of the product or experience. 0, qualities that were once amusing are becoming irritating . 0, everything's serious , poetic , earnest and -- sadly -- dull . 1, what's infuriating about full frontal is that it's too close to real l 0, befuddled in its characterizations as it begins to seem as long as the 0, human nature talks the talk , but it fails to walk the silly walk that ---------------------------------------------------------------------------------------------------- # Reading a review which belong to each group. rev_per_cluster = n_clusters for i in range(n_clusters): print(f\"Cluster {i} Theme:\", end=\" \") reviews = \"\\n\".join( df[df['cluster'] == i] .text.str.replace(\"Title: \", \"\") .str.replace(\"\\n\\nContent: \", \": \") .sample(rev_per_cluster, random_state=42) .values ) response = openai.Completion.create( engine=\"text-davinci-003\", prompt=f'What do the following customer reviews have in common?\\n\\nCustomer reviews:\\n\"\"\"\\n{reviews}\\n\"\"\"\\n\\nTheme:', temperature=0, max_tokens=64, top_p=1, frequency_penalty=0, presence_penalty=0, ) print(response[\"choices\"][0][\"text\"].replace(\"\\n\", \"\")) sample_cluster_rows = df[df.cluster == i].sample(rev_per_cluster, random_state=42) for j in range(rev_per_cluster): print(sample_cluster_rows.label.values[j], end=\", \") print(sample_cluster_rows.text.str[:70].values[j]) print(\"-\" * 100) Insight The Rotten Tomatoes movie reviews can be clearly classified into 2 categories: positive reviews (cluster 3) and negative reviews (cluster 2, 1, 0, \u0026 4). With the 2d/3d visuals, we can zoom in and see that the orange postive reviews can be distinguished from the other three negative review clusters.\nFurther Exploration Other use cases and their application Learning \u0026 Thought Clustering Business Use Cases [Assistant] Categorization tasks Categorize documents (Doc2Vec) Identify collaborators Discover mood patterns from notes \u0026 diary Organize bookmarks [Personalization] Understand user behavior - recommendations, search, mood [Operations] Identify fraudulent users Triage and tag tickets or reports ",
  "wordCount" : "1697",
  "inLanguage": "en",
  "datePublished": "2023-11-14T00:00:00Z",
  "dateModified": "2023-11-14T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Run Zhou"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://runrunicd.github.io/blog/posts/2023-11-14-embeddings/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Shel (Run) Zhou's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://runrunicd.github.io/blog/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://runrunicd.github.io/blog/" accesskey="h" title="Shel (Run) Zhou&#39;s Blog (Alt + H)">Shel (Run) Zhou&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://runrunicd.github.io/blog/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://runrunicd.github.io/blog/bodymindsoul/" title="Body, Mind, Soul">
                    <span>Body, Mind, Soul</span>
                </a>
            </li>
            <li>
                <a href="https://runrunicd.github.io/blog/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://runrunicd.github.io/blog/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://runrunicd.github.io/blog/">Home</a>&nbsp;»&nbsp;<a href="https://runrunicd.github.io/blog/posts/">Posts</a></div>
    <h1 class="post-title">
      Embeddings Use Cases
    </h1>
    <div class="post-meta"><span title='2023-11-14 00:00:00 +0000 UTC'>November 14, 2023</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Run Zhou

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#goals" aria-label="Goals">Goals</a></li>
                <li>
                    <a href="#what-do-you-need-to-know-about-embeddings" aria-label="What do you need to know about embeddings?">What do you need to know about embeddings?</a></li>
                <li>
                    <a href="#use-cases" aria-label="Use Cases">Use Cases</a><ul>
                        
                <li>
                    <a href="#clustering" aria-label="Clustering">Clustering</a><ul>
                        
                <li>
                    <a href="#2d-visualization-from-t-sne" aria-label="2D visualization from t-SNE">2D visualization from t-SNE</a></li>
                <li>
                    <a href="#2d-visualization-from-pca" aria-label="2D visualization from PCA">2D visualization from PCA</a></li>
                <li>
                    <a href="#3d-visualization-from-t-sne" aria-label="3D visualization from t-SNE">3D visualization from t-SNE</a></li>
                <li>
                    <a href="#cluster-theme" aria-label="Cluster theme">Cluster theme</a></li>
                <li>
                    <a href="#insight" aria-label="Insight">Insight</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#further-exploration" aria-label="Further Exploration">Further Exploration</a></li>
                <li>
                    <a href="#learning--thought" aria-label="Learning &amp;amp; Thought">Learning &amp; Thought</a><ul>
                        
                <li>
                    <a href="#clustering-business-use-cases" aria-label="Clustering Business Use Cases">Clustering Business Use Cases</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>When I first heard about text embeddings, I was perplexed. My tech lead handed me an 800-page Natural Language Processing textbook, but I did not finish reading it. Now, with the capabilities of OpenAI models, it&rsquo;s time to learn and broadly leverage embeddings to accomplish many tasks that were hard be achieved by human labor or simple data analysis, thanks to easy access to these embeddings.</p>
<p>Let&rsquo;s start exploring:</p>
<ul>
<li>Clustering</li>
<li>Search</li>
<li>Recommendations</li>
<li>Classification</li>
<li>Anomaly detection</li>
</ul>
<h2 id="goals">Goals<a hidden class="anchor" aria-hidden="true" href="#goals">#</a></h2>
<p>The ultimate goal is to become familiar with the framework of leveraging embeddings to accomplish applicable tasks. The best way to learn and improvise is first by getting your hands dirty with the data and tools. Optimization and deep-diving happen later naturally.</p>
<ul>
<li>Summarize key terminology, concept, and usage of text embeddings</li>
<li>Build the basic framework and standardized iPython notebooks for each use case that could benefit from text embeddings</li>
<li>Brainstorm business use cases and ideas for improvements</li>
</ul>
<h2 id="what-do-you-need-to-know-about-embeddings">What do you need to know about embeddings?<a hidden class="anchor" aria-hidden="true" href="#what-do-you-need-to-know-about-embeddings">#</a></h2>
<ul>
<li>An embedding is a vector (list) of floating point numbers, representing a text string.</li>
<li>The distance between two embeddings (vectors) measures their relatedness. The smaller the distance, the higher they are related, vice versa.</li>
<li>Dimensionality reduction methods:
<ul>
<li>t-SNE, a non-linear dimension reduction method, which stands for t-distributed Stochastic Neighbor Embedding. The ML algorithm calculates the similarity in both high dimensional sapce and low dimensional space, then the similarity difference in both spaces is minimized using an optimization method, for instance, gradient descend. It was developed by Laurens van der Maaten and Geoffrey Hinton in 2008. Here&rsquo;s a brief overview of what t-SNE does and how it work.</li>
<li>PCA, a linear dimension reduction method, where the data in high dimensional space is mapped linearly into low dimensional space while maximizing the variance of the data.</li>
</ul>
</li>
</ul>
<h2 id="use-cases">Use Cases<a hidden class="anchor" aria-hidden="true" href="#use-cases">#</a></h2>
<h3 id="clustering">Clustering<a hidden class="anchor" aria-hidden="true" href="#clustering">#</a></h3>
<p>Can we identify clusters among movie reviews and their themes? It&rsquo;s going to be difficult to review through all reviews and identify clusters of movie reviews. With AI, we can achieve that and I&rsquo;ll demo it here. Let&rsquo;s use <a href="https://huggingface.co/datasets/rotten_tomatoes">Rotten Tomatoes dataset</a>. To obtain text embeddings, let&rsquo;s use OpenAI&rsquo;s embeddings API and the model text-embedding-ada-002 is recommended. Note: all the code and data are open to public.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># Ensure you have your API key set in your environment per the README: https://github.com/openai/openai-python#usage</span>
</span></span><span class="line"><span class="cl">import openai
</span></span><span class="line"><span class="cl">openai.api_key <span class="o">=</span> <span class="s1">&#39;[openai_key]&#39;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">import pandas as pd
</span></span><span class="line"><span class="cl">import numpy as np
</span></span><span class="line"><span class="cl">import tiktoken
</span></span><span class="line"><span class="cl">import sys
</span></span><span class="line"><span class="cl">from typing import List, Optional
</span></span><span class="line"><span class="cl">from sklearn.manifold import TSNE
</span></span><span class="line"><span class="cl">from ast import literal_eval
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Now try to import your module again</span>
</span></span><span class="line"><span class="cl">def get_embedding<span class="o">(</span>text: str, <span class="nv">engine</span><span class="o">=</span><span class="s2">&#34;text-similarity-davinci-001&#34;</span>, **kwargs<span class="o">)</span> -&gt; List<span class="o">[</span>float<span class="o">]</span>:
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># replace newlines, which can negatively affect performance.</span>
</span></span><span class="line"><span class="cl">    <span class="nv">text</span> <span class="o">=</span> text.replace<span class="o">(</span><span class="s2">&#34;\n&#34;</span>, <span class="s2">&#34; &#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> openai.Embedding.create<span class="o">(</span><span class="nv">input</span><span class="o">=[</span>text<span class="o">]</span>, <span class="nv">engine</span><span class="o">=</span>engine, **kwargs<span class="o">)[</span><span class="s2">&#34;data&#34;</span><span class="o">][</span>0<span class="o">][</span><span class="s2">&#34;embedding&#34;</span><span class="o">]</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># Embedding model parameters</span>
</span></span><span class="line"><span class="cl"><span class="nv">embedding_model</span> <span class="o">=</span> <span class="s2">&#34;text-embedding-ada-002&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nv">embedding_encoding</span> <span class="o">=</span> <span class="s2">&#34;cl100k_base&#34;</span>  <span class="c1"># this the encoding for text-embedding-ada-002</span>
</span></span><span class="line"><span class="cl"><span class="nv">max_tokens</span> <span class="o">=</span> <span class="m">8000</span>  <span class="c1"># the maximum for text-embedding-ada-002 is 8191</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">from datasets import load_dataset
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nv">dataset</span> <span class="o">=</span> load_dataset<span class="o">(</span><span class="s2">&#34;rotten_tomatoes&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl"><span class="nv">df</span> <span class="o">=</span> dataset<span class="o">[</span><span class="s1">&#39;train&#39;</span><span class="o">]</span>.to_pandas<span class="o">()</span>
</span></span><span class="line"><span class="cl">print<span class="o">(</span><span class="s2">&#34;{x} rows in df.&#34;</span>.format<span class="o">(</span><span class="nv">x</span><span class="o">=</span>len<span class="o">(</span>df<span class="o">)))</span>
</span></span></code></pre></div><p><br></br></p>
<p>This is the sample data. The label is either 1 for positive sentiment or 0 for negative sentiment for the movie reviews.</p>
<table>
<thead>
<tr>
<th>text</th>
<th>label</th>
</tr>
</thead>
<tbody>
<tr>
<td>the rock is destined to be the 21st century&rsquo;s &hellip;</td>
<td>1</td>
</tr>
<tr>
<td>the gorgeously elaborate continuation of &quot; the&hellip;</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>Here, we get embeddings for the top 5000 move reviews.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nv">top_n</span> <span class="o">=</span> <span class="m">5000</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nv">encoding</span> <span class="o">=</span> tiktoken.get_encoding<span class="o">(</span>embedding_encoding<span class="o">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># omit reviews that are too long to embed</span>
</span></span><span class="line"><span class="cl">df<span class="o">[</span><span class="s2">&#34;n_tokens&#34;</span><span class="o">]</span> <span class="o">=</span> df<span class="o">[</span><span class="s1">&#39;text&#39;</span><span class="o">]</span>.apply<span class="o">(</span>lambda x: len<span class="o">(</span>encoding.encode<span class="o">(</span>x<span class="o">)))</span>
</span></span><span class="line"><span class="cl"><span class="nv">df</span> <span class="o">=</span> df<span class="o">[</span>df.n_tokens &lt;<span class="o">=</span> max_tokens<span class="o">]</span>.tail<span class="o">(</span>top_n<span class="o">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># get embeddings and save them</span>
</span></span><span class="line"><span class="cl">df<span class="o">[</span><span class="s2">&#34;embedding&#34;</span><span class="o">]</span> <span class="o">=</span> df<span class="o">[</span><span class="s1">&#39;text&#39;</span><span class="o">]</span>.apply<span class="o">(</span>lambda x: get_embedding<span class="o">(</span>x, <span class="nv">engine</span><span class="o">=</span>embedding_model<span class="o">))</span>
</span></span><span class="line"><span class="cl">df.to_csv<span class="o">(</span><span class="s2">&#34;./rotten_tomatoes_with_embeddings_{x}.csv&#34;</span>.format<span class="o">(</span><span class="nv">x</span><span class="o">=</span>top_n<span class="o">))</span>
</span></span></code></pre></div><p>Apply Kmeans algorithm to the embeddings to identify clusters.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">import numpy as np
</span></span><span class="line"><span class="cl">from sklearn.cluster import KMeans
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Convert to a list of lists of floats</span>
</span></span><span class="line"><span class="cl"><span class="nv">matrix</span> <span class="o">=</span> np.vstack<span class="o">(</span>df.embedding.apply<span class="o">(</span>literal_eval<span class="o">)</span>.to_list<span class="o">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nv">n_clusters</span> <span class="o">=</span> <span class="m">5</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nv">kmeans</span> <span class="o">=</span> KMeans<span class="o">(</span><span class="nv">n_clusters</span><span class="o">=</span>n_clusters, <span class="nv">init</span><span class="o">=</span><span class="s1">&#39;k-means++&#39;</span>, <span class="nv">random_state</span><span class="o">=</span>42<span class="o">)</span>
</span></span><span class="line"><span class="cl">kmeans.fit<span class="o">(</span>matrix<span class="o">)</span>
</span></span><span class="line"><span class="cl">df<span class="o">[</span><span class="s1">&#39;cluster&#39;</span><span class="o">]</span> <span class="o">=</span> kmeans.labels_
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">df.groupby<span class="o">(</span><span class="s2">&#34;cluster&#34;</span><span class="o">)</span>.label.mean<span class="o">()</span>.sort_values<span class="o">()</span>
</span></span></code></pre></div><p>We can see that the mean of label values varies by cluster, suggesting that the sentiments are separated by the clustering, espectially cluster (2), cluster (1, 0, 4), and cluster (3).</p>
<table>
<thead>
<tr>
<th>Cluster</th>
<th>Mean</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td>0.010241</td>
</tr>
<tr>
<td>1</td>
<td>0.091311</td>
</tr>
<tr>
<td>0</td>
<td>0.099548</td>
</tr>
<tr>
<td>4</td>
<td>0.113420</td>
</tr>
<tr>
<td>3</td>
<td>0.480874</td>
</tr>
</tbody>
</table>
<p>To visualize the clusters, transform the embeddings of high-dimension 1536 to 2D by t-SNE.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">from sklearn.manifold import TSNE
</span></span><span class="line"><span class="cl">import matplotlib
</span></span><span class="line"><span class="cl">import matplotlib.pyplot as plt
</span></span><span class="line"><span class="cl">import plotly.express as px
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nv">tsne</span> <span class="o">=</span> TSNE<span class="o">(</span><span class="nv">n_components</span><span class="o">=</span>2, <span class="nv">perplexity</span><span class="o">=</span>15, <span class="nv">random_state</span><span class="o">=</span>42, <span class="nv">init</span><span class="o">=</span><span class="s2">&#34;random&#34;</span>, <span class="nv">learning_rate</span><span class="o">=</span>200<span class="o">)</span>
</span></span><span class="line"><span class="cl"><span class="nv">vis_dims2</span> <span class="o">=</span> tsne.fit_transform<span class="o">(</span>matrix<span class="o">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Define the color map for the clusters</span>
</span></span><span class="line"><span class="cl"><span class="nv">color_map</span> <span class="o">=</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">    0: <span class="s1">&#39;firebrick&#39;</span>,         <span class="c1"># Cluster 0</span>
</span></span><span class="line"><span class="cl">    1: <span class="s1">&#39;orangered&#39;</span>,  <span class="c1"># Cluster 1</span>
</span></span><span class="line"><span class="cl">    2: <span class="s1">&#39;gold&#39;</span>,      <span class="c1"># Cluster 2</span>
</span></span><span class="line"><span class="cl">    3: <span class="s1">&#39;limegreen&#39;</span>,       <span class="c1"># Cluster 3</span>
</span></span><span class="line"><span class="cl">    4: <span class="s1">&#39;maroon&#39;</span>       <span class="c1"># Cluster 4</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Map the cluster labels to colors</span>
</span></span><span class="line"><span class="cl">df<span class="o">[</span><span class="s1">&#39;color&#39;</span><span class="o">]</span> <span class="o">=</span> df<span class="o">[</span><span class="s1">&#39;cluster&#39;</span><span class="o">]</span>.map<span class="o">(</span>color_map<span class="o">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Convert cluster to a categorical type with the specified order</span>
</span></span><span class="line"><span class="cl">df<span class="o">[</span><span class="s1">&#39;cluster&#39;</span><span class="o">]</span> <span class="o">=</span> pd.Categorical<span class="o">(</span>df<span class="o">[</span><span class="s1">&#39;cluster&#39;</span><span class="o">]</span>, <span class="nv">categories</span><span class="o">=[</span>0, 1, 2, 3, 4<span class="o">]</span>, <span class="nv">ordered</span><span class="o">=</span>True<span class="o">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create a DataFrame from the t-SNE results</span>
</span></span><span class="line"><span class="cl"><span class="nv">df_tsne</span> <span class="o">=</span> pd.DataFrame<span class="o">({</span><span class="s1">&#39;Dimension 1&#39;</span>: vis_dims2<span class="o">[</span>:, 0<span class="o">]</span>, 
</span></span><span class="line"><span class="cl">                        <span class="s1">&#39;Dimension 2&#39;</span>: vis_dims2<span class="o">[</span>:, 1<span class="o">]</span>, 
</span></span><span class="line"><span class="cl">                        <span class="s1">&#39;Cluster&#39;</span>: df<span class="o">[</span><span class="s1">&#39;cluster&#39;</span><span class="o">]</span>,
</span></span><span class="line"><span class="cl">                        <span class="s1">&#39;Color&#39;</span>: df<span class="o">[</span><span class="s1">&#39;color&#39;</span><span class="o">]})</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create the 2D scatter plot using Plotly Express</span>
</span></span><span class="line"><span class="cl"><span class="nv">fig</span> <span class="o">=</span> px.scatter<span class="o">(</span>
</span></span><span class="line"><span class="cl">    df_tsne, <span class="nv">x</span><span class="o">=</span><span class="s1">&#39;Dimension 1&#39;</span>, <span class="nv">y</span><span class="o">=</span><span class="s1">&#39;Dimension 2&#39;</span>,
</span></span><span class="line"><span class="cl">    <span class="nv">color</span><span class="o">=</span><span class="s1">&#39;Cluster&#39;</span>, <span class="nv">labels</span><span class="o">={</span><span class="s1">&#39;Cluster&#39;</span>: <span class="s1">&#39;Cluster&#39;</span><span class="o">}</span>,
</span></span><span class="line"><span class="cl">    <span class="nv">title</span><span class="o">=</span><span class="s1">&#39;Clusters identified visualized in 2D using t-SNE&#39;</span>,
</span></span><span class="line"><span class="cl">    <span class="nv">color_discrete_map</span><span class="o">=</span>color_map <span class="c1"># Apply the color map</span>
</span></span><span class="line"><span class="cl"><span class="o">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Define the category orders for the legend to make it discrete</span>
</span></span><span class="line"><span class="cl">fig.update_traces<span class="o">(</span><span class="nv">marker</span><span class="o">=</span>dict<span class="o">(</span><span class="nv">size</span><span class="o">=</span>3<span class="o">)</span>, <span class="nv">selector</span><span class="o">=</span>dict<span class="o">(</span><span class="nv">mode</span><span class="o">=</span><span class="s1">&#39;markers&#39;</span><span class="o">))</span>  <span class="c1"># Adjust marker size</span>
</span></span><span class="line"><span class="cl">fig.update_layout<span class="o">(</span>
</span></span><span class="line"><span class="cl">    <span class="nv">legend</span><span class="o">=</span>dict<span class="o">(</span>
</span></span><span class="line"><span class="cl">        <span class="nv">traceorder</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span>,
</span></span><span class="line"><span class="cl">        <span class="nv">title_text</span><span class="o">=</span><span class="s1">&#39;Cluster&#39;</span>,
</span></span><span class="line"><span class="cl">        <span class="nv">title_font</span><span class="o">=</span>dict<span class="o">(</span><span class="nv">size</span><span class="o">=</span>14<span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">)</span>
</span></span><span class="line"><span class="cl"><span class="o">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Show the plot</span>
</span></span><span class="line"><span class="cl">fig.show<span class="o">()</span>
</span></span></code></pre></div><p><br></br></p>
<h4 id="2d-visualization-from-t-sne">2D visualization from t-SNE<a hidden class="anchor" aria-hidden="true" href="#2d-visualization-from-t-sne">#</a></h4>
<p>We can identify the clusters by the differently colored dense cores.<br>
<img loading="lazy" src="images/2d_tsne.png#center" alt="2D visualization of clusters"  />

<br></br></p>
<h4 id="2d-visualization-from-pca">2D visualization from PCA<a hidden class="anchor" aria-hidden="true" href="#2d-visualization-from-pca">#</a></h4>
<p>It&rsquo;s exploratory, so it&rsquo;s worthwhile to see PCA 2D results too. We label positive reviews green and negative red.
<img loading="lazy" src="images/2d_pca.png#center" alt="2D visualization of clusters"  />

<br></br></p>
<h4 id="3d-visualization-from-t-sne">3D visualization from t-SNE<a hidden class="anchor" aria-hidden="true" href="#3d-visualization-from-t-sne">#</a></h4>
<p>Sometimes, it&rsquo;s helpful to identify clusters in 3D visualization as there might be more than two major forces critical in classifying the move reviews. You may wonder why are the movie reviews in each cluster grouped together? When we go on to the next section, we may see that the green cluster is for positive reviews and the other four are quite negative.
<br></br></p>

<iframe width="100%" height="550" name="iframe", src="iframes/3d_tsne.html"></iframe>



<p><br></br></p>
<h4 id="cluster-theme">Cluster theme<a hidden class="anchor" aria-hidden="true" href="#cluster-theme">#</a></h4>
<p>Furthermore, we can leverage the model text-davinci-003 to summarize the theme for each cluster of movie reviews on Rotten Tomatoes.</p>
<p>Let’s summarize the clusters, the mean sentiment, and the theme. Cluster 2 is very negative, expressing disappointment with the movies. In contrast, cluster 3 is very positive, with praise. Finally, clusters 1, 0, and 4 are closer to negative reviews but are not as disappointed as cluster 2.</p>
<table>
<thead>
<tr>
<th>Cluster</th>
<th>Mean Sentiment</th>
<th>Theme</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td>0.010241</td>
<td>Disappointed with the quality of the movie.</td>
</tr>
<tr>
<td>1</td>
<td>0.091311</td>
<td>The reviews are all negative and critical of the movie.</td>
</tr>
<tr>
<td>0</td>
<td>0.099548</td>
<td>All of the reviews are negative and express dissatisfaction with the product or experience.</td>
</tr>
<tr>
<td>4</td>
<td>0.113420</td>
<td>Disappointment with the quality of the product or experience.</td>
</tr>
<tr>
<td>3</td>
<td>0.480874</td>
<td>All of the reviews are positive and praise the movie for its unique qualities, such as its surreal sense of humor, technological finish, insightful writing, delicate performances, and character-driven storytelling.</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-txt" data-lang="txt"><span class="line"><span class="cl">Cluster 0 Theme:  All of the reviews are negative and express dissatisfaction with the product or experience.
</span></span><span class="line"><span class="cl">1, now as a former gong show addict , i&#39;ll admit it , my only complaint i
</span></span><span class="line"><span class="cl">0, there&#39;s just no currency in deriding james bond for being a clichéd , 
</span></span><span class="line"><span class="cl">0, ecks this one off your must-see list .
</span></span><span class="line"><span class="cl">0, skip this turd and pick your nose instead because you&#39;re sure to get m
</span></span><span class="line"><span class="cl">0, this movie is about the worst thing chan has done in the united states
</span></span><span class="line"><span class="cl">----------------------------------------------------------------------------------------------------
</span></span><span class="line"><span class="cl">Cluster 1 Theme:  The reviews are all negative and critical of the movie.
</span></span><span class="line"><span class="cl">0, the type of dumbed-down exercise in stereotypes that gives the [teen c
</span></span><span class="line"><span class="cl">0, just not campy enough
</span></span><span class="line"><span class="cl">0, not so much farcical as sour .
</span></span><span class="line"><span class="cl">0, a one-trick pony whose few t&amp;a bits still can&#39;t save itself from being
</span></span><span class="line"><span class="cl">0, cuba gooding jr . valiantly mugs his way through snow dogs , but even 
</span></span><span class="line"><span class="cl">----------------------------------------------------------------------------------------------------
</span></span><span class="line"><span class="cl">Cluster 2 Theme:  Disappointed with the quality of the movie.
</span></span><span class="line"><span class="cl">0, its generic villains lack any intrigue ( other than their funny accent
</span></span><span class="line"><span class="cl">0, one of the most highly-praised disappointments i&#39;ve had the misfortune
</span></span><span class="line"><span class="cl">0, . . . with the candy-like taste of it fading faster than 25-cent bubbl
</span></span><span class="line"><span class="cl">0, for all its impressive craftsmanship , and despite an overbearing seri
</span></span><span class="line"><span class="cl">0, the script by vincent r . nebrida . . . tries to cram too many ingredi
</span></span><span class="line"><span class="cl">----------------------------------------------------------------------------------------------------
</span></span><span class="line"><span class="cl">Cluster 3 Theme:  All of the reviews are positive and praise the movie for its unique qualities, such as its surreal sense of humor, technological finish, insightful writing, delicate performances, and character-driven storytelling.
</span></span><span class="line"><span class="cl">1, what elevates the movie above the run-of-the-mill singles blender is i
</span></span><span class="line"><span class="cl">0, at least it&#39;s a fairly impressive debut from the director , charles st
</span></span><span class="line"><span class="cl">1, insightfully written , delicately performed
</span></span><span class="line"><span class="cl">1, one of those exceedingly rare films in which the talk alone is enough 
</span></span><span class="line"><span class="cl">1, a stylish but steady , and ultimately very satisfying , piece of chara
</span></span><span class="line"><span class="cl">----------------------------------------------------------------------------------------------------
</span></span><span class="line"><span class="cl">Cluster 4 Theme:  Disappointment with the quality of the product or experience.
</span></span><span class="line"><span class="cl">0, qualities that were once amusing are becoming irritating .
</span></span><span class="line"><span class="cl">0, everything&#39;s serious , poetic , earnest and -- sadly -- dull .
</span></span><span class="line"><span class="cl">1, what&#39;s infuriating about full frontal is that it&#39;s too close to real l
</span></span><span class="line"><span class="cl">0, befuddled in its characterizations as it begins to seem as long as the
</span></span><span class="line"><span class="cl">0, human nature talks the talk , but it fails to walk the silly walk that
</span></span><span class="line"><span class="cl">----------------------------------------------------------------------------------------------------
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># Reading a review which belong to each group.</span>
</span></span><span class="line"><span class="cl"><span class="nv">rev_per_cluster</span> <span class="o">=</span> n_clusters
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> i in range<span class="o">(</span>n_clusters<span class="o">)</span>:
</span></span><span class="line"><span class="cl">    print<span class="o">(</span>f<span class="s2">&#34;Cluster {i} Theme:&#34;</span>, <span class="nv">end</span><span class="o">=</span><span class="s2">&#34; &#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nv">reviews</span> <span class="o">=</span> <span class="s2">&#34;\n&#34;</span>.join<span class="o">(</span>
</span></span><span class="line"><span class="cl">        df<span class="o">[</span>df<span class="o">[</span><span class="s1">&#39;cluster&#39;</span><span class="o">]</span> <span class="o">==</span> i<span class="o">]</span>
</span></span><span class="line"><span class="cl">        .text.str.replace<span class="o">(</span><span class="s2">&#34;Title: &#34;</span>, <span class="s2">&#34;&#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">        .str.replace<span class="o">(</span><span class="s2">&#34;\n\nContent: &#34;</span>, <span class="s2">&#34;:  &#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">        .sample<span class="o">(</span>rev_per_cluster, <span class="nv">random_state</span><span class="o">=</span>42<span class="o">)</span>
</span></span><span class="line"><span class="cl">        .values
</span></span><span class="line"><span class="cl">    <span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="nv">response</span> <span class="o">=</span> openai.Completion.create<span class="o">(</span>
</span></span><span class="line"><span class="cl">        <span class="nv">engine</span><span class="o">=</span><span class="s2">&#34;text-davinci-003&#34;</span>,
</span></span><span class="line"><span class="cl">        <span class="nv">prompt</span><span class="o">=</span>f<span class="s1">&#39;What do the following customer reviews have in common?\n\nCustomer reviews:\n&#34;&#34;&#34;\n{reviews}\n&#34;&#34;&#34;\n\nTheme:&#39;</span>,
</span></span><span class="line"><span class="cl">        <span class="nv">temperature</span><span class="o">=</span>0,
</span></span><span class="line"><span class="cl">        <span class="nv">max_tokens</span><span class="o">=</span>64,
</span></span><span class="line"><span class="cl">        <span class="nv">top_p</span><span class="o">=</span>1,
</span></span><span class="line"><span class="cl">        <span class="nv">frequency_penalty</span><span class="o">=</span>0,
</span></span><span class="line"><span class="cl">        <span class="nv">presence_penalty</span><span class="o">=</span>0,
</span></span><span class="line"><span class="cl">    <span class="o">)</span>
</span></span><span class="line"><span class="cl">    print<span class="o">(</span>response<span class="o">[</span><span class="s2">&#34;choices&#34;</span><span class="o">][</span>0<span class="o">][</span><span class="s2">&#34;text&#34;</span><span class="o">]</span>.replace<span class="o">(</span><span class="s2">&#34;\n&#34;</span>, <span class="s2">&#34;&#34;</span><span class="o">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nv">sample_cluster_rows</span> <span class="o">=</span> df<span class="o">[</span>df.cluster <span class="o">==</span> i<span class="o">]</span>.sample<span class="o">(</span>rev_per_cluster, <span class="nv">random_state</span><span class="o">=</span>42<span class="o">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> j in range<span class="o">(</span>rev_per_cluster<span class="o">)</span>:
</span></span><span class="line"><span class="cl">        print<span class="o">(</span>sample_cluster_rows.label.values<span class="o">[</span>j<span class="o">]</span>, <span class="nv">end</span><span class="o">=</span><span class="s2">&#34;, &#34;</span><span class="o">)</span>
</span></span><span class="line"><span class="cl">        print<span class="o">(</span>sample_cluster_rows.text.str<span class="o">[</span>:70<span class="o">]</span>.values<span class="o">[</span>j<span class="o">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    print<span class="o">(</span><span class="s2">&#34;-&#34;</span> * 100<span class="o">)</span>
</span></span></code></pre></div><h4 id="insight">Insight<a hidden class="anchor" aria-hidden="true" href="#insight">#</a></h4>
<p>The Rotten Tomatoes movie reviews can be clearly classified into 2 categories: positive reviews (cluster 3) and negative reviews (cluster 2, 1, 0, &amp; 4). With the 2d/3d visuals, we can zoom in and see that the orange postive reviews can be distinguished from the other three negative review clusters.</p>
<h2 id="further-exploration">Further Exploration<a hidden class="anchor" aria-hidden="true" href="#further-exploration">#</a></h2>
<ul>
<li>Other use cases and their application</li>
</ul>
<h2 id="learning--thought">Learning &amp; Thought<a hidden class="anchor" aria-hidden="true" href="#learning--thought">#</a></h2>
<h3 id="clustering-business-use-cases">Clustering Business Use Cases<a hidden class="anchor" aria-hidden="true" href="#clustering-business-use-cases">#</a></h3>
<ol>
<li>[Assistant] Categorization tasks
<ul>
<li>Categorize documents (Doc2Vec)</li>
<li>Identify collaborators</li>
<li>Discover mood patterns from notes &amp; diary</li>
<li>Organize bookmarks</li>
</ul>
</li>
<li>[Personalization]
<ul>
<li>Understand user behavior - recommendations, search, mood</li>
</ul>
</li>
<li>[Operations]
<ul>
<li>Identify fraudulent users</li>
<li>Triage and tag tickets or reports</li>
</ul>
</li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://runrunicd.github.io/blog/tags/large-language-model/">large-language-model</a></li>
      <li><a href="https://runrunicd.github.io/blog/tags/embeddings/">embeddings</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://runrunicd.github.io/blog/posts/2024-01-22-rag/">
    <span class="title">« Prev</span>
    <br>
    <span>Everything about RAG</span>
  </a>
  <a class="next" href="https://runrunicd.github.io/blog/posts/2023-08-28-llm-fine-tuning/">
    <span class="title">Next »</span>
    <br>
    <span>Build a Simple Framework for LLM Fine-Tuning on TPU &amp; Share Insight on Applications</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Embeddings Use Cases on twitter"
        href="https://twitter.com/intent/tweet/?text=Embeddings%20Use%20Cases&amp;url=https%3a%2f%2frunrunicd.github.io%2fblog%2fposts%2f2023-11-14-embeddings%2f&amp;hashtags=large-language-model%2cembeddings">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Embeddings Use Cases on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2frunrunicd.github.io%2fblog%2fposts%2f2023-11-14-embeddings%2f&amp;title=Embeddings%20Use%20Cases&amp;summary=Embeddings%20Use%20Cases&amp;source=https%3a%2f%2frunrunicd.github.io%2fblog%2fposts%2f2023-11-14-embeddings%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Embeddings Use Cases on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2frunrunicd.github.io%2fblog%2fposts%2f2023-11-14-embeddings%2f&title=Embeddings%20Use%20Cases">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Embeddings Use Cases on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2frunrunicd.github.io%2fblog%2fposts%2f2023-11-14-embeddings%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Embeddings Use Cases on whatsapp"
        href="https://api.whatsapp.com/send?text=Embeddings%20Use%20Cases%20-%20https%3a%2f%2frunrunicd.github.io%2fblog%2fposts%2f2023-11-14-embeddings%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Embeddings Use Cases on telegram"
        href="https://telegram.me/share/url?text=Embeddings%20Use%20Cases&amp;url=https%3a%2f%2frunrunicd.github.io%2fblog%2fposts%2f2023-11-14-embeddings%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Embeddings Use Cases on ycombinator"
        href="https://news.ycombinator.com/submitlink?t=Embeddings%20Use%20Cases&u=https%3a%2f%2frunrunicd.github.io%2fblog%2fposts%2f2023-11-14-embeddings%2f">
        <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
            xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
            <path
                d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://runrunicd.github.io/blog/">Shel (Run) Zhou&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
