<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Learning Notes on Large Language Model (Dumping Knowledge for Now) | Shel (Run) Zhou&#39;s Blog</title>
<meta name="keywords" content="large-language-model">
<meta name="description" content="Messy &hellip; Introduction to Large Language Model Auto-regressive transformers are pretrained on an extensive corpus of self-supervised data, followed by alignment with human preferences via techniques such as Reinforcement Learning with Human Feedback (RLHF).
Training methodology is simple but is limited to a few players with high computational requirements
Public pretrained LLM
BLOOM (Scao et al., 2022) LLaMa 1 (Touvron et al., 2023) LLaMa 2, LLaMa 2-Chat which is optimized for dialogue use cases Falcon (Penedo et al.">
<meta name="author" content="Run Zhou">
<link rel="canonical" href="https://runrunicd.github.io/blog/post/2023-08-28-llm-reading-notes/">
<link crossorigin="anonymous" href="/blog/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css" integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U&#43;6hYRq/Ez/nm5vg=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/blog/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://runrunicd.github.io/blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://runrunicd.github.io/blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://runrunicd.github.io/blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://runrunicd.github.io/blog/apple-touch-icon.png">
<link rel="mask-icon" href="https://runrunicd.github.io/blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Learning Notes on Large Language Model (Dumping Knowledge for Now)" />
<meta property="og:description" content="Messy &hellip; Introduction to Large Language Model Auto-regressive transformers are pretrained on an extensive corpus of self-supervised data, followed by alignment with human preferences via techniques such as Reinforcement Learning with Human Feedback (RLHF).
Training methodology is simple but is limited to a few players with high computational requirements
Public pretrained LLM
BLOOM (Scao et al., 2022) LLaMa 1 (Touvron et al., 2023) LLaMa 2, LLaMa 2-Chat which is optimized for dialogue use cases Falcon (Penedo et al." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://runrunicd.github.io/blog/post/2023-08-28-llm-reading-notes/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-08-01T13:33:00-07:00" />
<meta property="article:modified_time" content="2023-08-01T13:33:00-07:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Learning Notes on Large Language Model (Dumping Knowledge for Now)"/>
<meta name="twitter:description" content="Messy &hellip; Introduction to Large Language Model Auto-regressive transformers are pretrained on an extensive corpus of self-supervised data, followed by alignment with human preferences via techniques such as Reinforcement Learning with Human Feedback (RLHF).
Training methodology is simple but is limited to a few players with high computational requirements
Public pretrained LLM
BLOOM (Scao et al., 2022) LLaMa 1 (Touvron et al., 2023) LLaMa 2, LLaMa 2-Chat which is optimized for dialogue use cases Falcon (Penedo et al."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://runrunicd.github.io/blog/post/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Learning Notes on Large Language Model (Dumping Knowledge for Now)",
      "item": "https://runrunicd.github.io/blog/post/2023-08-28-llm-reading-notes/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Learning Notes on Large Language Model (Dumping Knowledge for Now)",
  "name": "Learning Notes on Large Language Model (Dumping Knowledge for Now)",
  "description": "Messy \u0026hellip; Introduction to Large Language Model Auto-regressive transformers are pretrained on an extensive corpus of self-supervised data, followed by alignment with human preferences via techniques such as Reinforcement Learning with Human Feedback (RLHF).\nTraining methodology is simple but is limited to a few players with high computational requirements\nPublic pretrained LLM\nBLOOM (Scao et al., 2022) LLaMa 1 (Touvron et al., 2023) LLaMa 2, LLaMa 2-Chat which is optimized for dialogue use cases Falcon (Penedo et al.",
  "keywords": [
    "large-language-model"
  ],
  "articleBody": "Messy … Introduction to Large Language Model Auto-regressive transformers are pretrained on an extensive corpus of self-supervised data, followed by alignment with human preferences via techniques such as Reinforcement Learning with Human Feedback (RLHF).\nTraining methodology is simple but is limited to a few players with high computational requirements\nPublic pretrained LLM\nBLOOM (Scao et al., 2022) LLaMa 1 (Touvron et al., 2023) LLaMa 2, LLaMa 2-Chat which is optimized for dialogue use cases Falcon (Penedo et al., 2023) Closed pretrained LLM\nGPT-3 (Brown et al., 2020) Chinchilla (Hoffmann et al., 2022) Closed “product” LLM that are heavily fine-tuned to align with human preferences to enhance their usability and safety\nChatGPT (OpenAI) BARD (Google) Claude (Antropic) Pretraining Use standard transformer architecture From LLaMa 1 to LLaMa 2, increased context length and grouped-query attention (GQA) Apply pre-normalization using RMSNorm Use SwiGLU activation function \u0026 rotary positional embeddings Tokenizr - the same as LLaMa 1 Variables Params Context length Tokens Learning rate (LR) GQA Hyperparameters AdamW optimizer Learning rate schedule (warmup steps) Weight decay Gradient clipping Pretrained Model Evaluation Summarize the overall performance across a suite of popular benchmarks. (Image Source: Touvron et al. 2023) Fine-Tuning Llama 2-Chat is the result of several months of research and iterative applications of alignment techniques, including both instruction tuning and RLHF, requiring significant computational and annotation resources.\nSupervised fine-tuning (SFT) with iterative reward modeling and RLHF\nAnnotators have written both the prompt and its answer\nhelpfulness: how well Llama 2-Chat responses fulfill users’ requests and provide requested information safety: whether Llama 2-Chat’s responses are unsafe Find-tuning started with the SFT stage with publicly available instruction tuning data (Chung et al., 2022)\nTo improve alignment, high-quality vendor-based SFT data in the order of tens of thousands is shown to improve the results (Touvron et al. 2023)\nData checks are important as different annotation platforms and vendors result in different model performance (Touvron et al. 2023)\nRLHF is a model training procedure that is applied to a fine-tuned language model to further align model behavior with human preferences and instruction following.\nHuman Preference Data Collection: We ask annotators to first write a prompt, then choose between two sampled model responses, based on provided criteria. In order to maximize the diversity, the two responses to a given prompt are sampled from two different model variants, and varying the temperature hyper-parameter. In addition to giving participants a forced choice, we also ask annotators to label the degree to which they prefer their chosen response over the alternative: either their choice is significantly better, better, slightly better, or negligibly better/ unsure. (Touvron et al. 2023)\nReward Modeling: The reward model takes a model response and its corresponding prompt (including contexts from previous turns) as inputs and outputs a scalar score to indicate the quality (e.g., helpfulness and safety) of the model generation. Leveraging such response scores as rewards, we can optimize Llama 2-Chat during RLHF for better human preference alignment and improved helpfulness and safety. We train two separate reward models, one optimized for helpfulness (referred to as Helpfulness RM) and another for safety (Safety RM) to address helpfulness vs. safety trade-off.\nSystem Message for Multi-Turn Consistency: In a dialogue setup, the initial RLHF models tended to forget the initial instruction after a few turns of dialogue. To address these limitations, we propose Ghost Attention (GAtt), a very simple method inspired by Context Distillation (Bai et al., 2022b) that hacks the fine-tuning data to help the attention focus in a multi-stage process. GAtt enables dialogue control over multiple turns. (Image Source: Touvron et al. 2023) Human evaluation is often considered the gold standard for judging models for natural language generation, including dialogue models. To evaluate the quality of major model versions, we asked human evaluators to rate them on helpfulness and safety (Touvron et al. 2023). Limitations include:\nDoes not cover all real-world usage due to limited number of prompts Subjective to prompts and instructions Safety Use safety-specific data annotation and tuning, conduct red-teaming, and employ iterative evaluations. (Image Source: Touvron et al. 2023) Testing conducted to date has been in English and has not — and could not — cover all scenarios.\n(Image Source: Touvron et al. 2023) Safety Metrics\nTruthfulness Toxicity Bias Safety Annotation Guidelines\nillicit and criminal activities (e.g., terrorism, theft, human trafficking) hateful and harmful activities (e.g., defamation, self-harm, eating disorders discrimination) unqualified advice (e.g., medical advice, financial advice, legal advice) We then define best practices for safe and helpful model responses: the model should first address immediate safety concerns if applicable, then address the prompt by explaining the potential risks to the user, and finally provide additional information if possible (Touvron et al. 2023). Red Teaming\nvarious kinds of proactive risk identification, colloquially called “red teaming,“ based on the term commonly used within computer security (Touvron et al. 2023). Reference [1] Llama 2: Open Foundation and Fine-Tuned Chat Models (Touvron et al. 2023) ",
  "wordCount" : "818",
  "inLanguage": "en",
  "datePublished": "2023-08-01T13:33:00-07:00",
  "dateModified": "2023-08-01T13:33:00-07:00",
  "author":{
    "@type": "Person",
    "name": "Run Zhou"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://runrunicd.github.io/blog/post/2023-08-28-llm-reading-notes/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Shel (Run) Zhou's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://runrunicd.github.io/blog/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://runrunicd.github.io/blog/" accesskey="h" title="Shel (Run) Zhou&#39;s Blog (Alt + H)">Shel (Run) Zhou&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://runrunicd.github.io/blog/post/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://runrunicd.github.io/blog/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://runrunicd.github.io/blog/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://runrunicd.github.io/blog/books/" title="Books">
                    <span>Books</span>
                </a>
            </li>
            <li>
                <a href="https://runrunicd.github.io/blog/%E4%BF%AE/" title="修">
                    <span>修</span>
                </a>
            </li>
            <li>
                <a href="https://runrunicd.github.io/blog/vlog/" title="vlog">
                    <span>vlog</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://runrunicd.github.io/blog/">Home</a>&nbsp;»&nbsp;<a href="https://runrunicd.github.io/blog/post/">Posts</a></div>
    <h1 class="post-title">
      Learning Notes on Large Language Model (Dumping Knowledge for Now)
    </h1>
    <div class="post-meta"><span title='2023-08-01 13:33:00 -0700 -0700'>August 1, 2023</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Run Zhou

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#messy-" aria-label="Messy &amp;hellip;">Messy &hellip;</a></li>
                <li>
                    <a href="#introduction-to-large-language-model" aria-label="Introduction to Large Language Model">Introduction to Large Language Model</a></li>
                <li>
                    <a href="#pretraining" aria-label="Pretraining">Pretraining</a><ul>
                        <ul>
                        <ul>
                        
                <li>
                    <a href="#variables" aria-label="Variables">Variables</a></li>
                <li>
                    <a href="#hyperparameters" aria-label="Hyperparameters">Hyperparameters</a></li></ul>
                    
                <li>
                    <a href="#pretrained-model-evaluation" aria-label="Pretrained Model Evaluation">Pretrained Model Evaluation</a></li></ul>
                    </ul>
                </li>
                <li>
                    <a href="#fine-tuning" aria-label="Fine-Tuning">Fine-Tuning</a></li>
                <li>
                    <a href="#safety" aria-label="Safety">Safety</a></li>
                <li>
                    <a href="#reference" aria-label="Reference">Reference</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="messy-">Messy &hellip;<a hidden class="anchor" aria-hidden="true" href="#messy-">#</a></h2>
<h2 id="introduction-to-large-language-model">Introduction to Large Language Model<a hidden class="anchor" aria-hidden="true" href="#introduction-to-large-language-model">#</a></h2>
<ul>
<li>
<p>Auto-regressive transformers are pretrained on an extensive corpus of self-supervised data,
followed by alignment with human preferences via techniques such as Reinforcement Learning with Human
Feedback (RLHF).</p>
</li>
<li>
<p>Training methodology is simple but is limited to a few players with high computational requirements</p>
</li>
<li>
<p>Public pretrained LLM</p>
<ul>
<li>BLOOM (Scao et al., 2022)</li>
<li>LLaMa 1 (Touvron et al., 2023)</li>
<li>LLaMa 2, LLaMa 2-Chat which is optimized for dialogue use cases</li>
<li>Falcon (Penedo et al., 2023)</li>
</ul>
</li>
<li>
<p>Closed pretrained LLM</p>
<ul>
<li>GPT-3 (Brown et al., 2020)</li>
<li>Chinchilla (Hoffmann et al., 2022)</li>
</ul>
</li>
<li>
<p>Closed &ldquo;product&rdquo; LLM that are heavily fine-tuned to align with human preferences to enhance their usability and safety</p>
<ul>
<li>ChatGPT (OpenAI)</li>
<li>BARD (Google)</li>
<li>Claude (Antropic)</li>
</ul>
</li>
</ul>
<h2 id="pretraining">Pretraining<a hidden class="anchor" aria-hidden="true" href="#pretraining">#</a></h2>
<ul>
<li>Use standard transformer architecture
<ul>
<li>From LLaMa 1 to LLaMa 2, increased context length and grouped-query attention (GQA)</li>
</ul>
</li>
<li>Apply pre-normalization using RMSNorm</li>
<li>Use SwiGLU activation function &amp; rotary positional embeddings</li>
<li>Tokenizr - the same as LLaMa 1</li>
</ul>
<h5 id="variables">Variables<a hidden class="anchor" aria-hidden="true" href="#variables">#</a></h5>
<ul>
<li>Params</li>
<li>Context length</li>
<li>Tokens</li>
<li>Learning rate (LR)</li>
<li>GQA</li>
</ul>
<h5 id="hyperparameters">Hyperparameters<a hidden class="anchor" aria-hidden="true" href="#hyperparameters">#</a></h5>
<ul>
<li>AdamW optimizer</li>
<li>Learning rate schedule (warmup steps)</li>
<li>Weight decay</li>
<li>Gradient clipping</li>
</ul>
<h4 id="pretrained-model-evaluation">Pretrained Model Evaluation<a hidden class="anchor" aria-hidden="true" href="#pretrained-model-evaluation">#</a></h4>
<ul>
<li>Summarize the overall performance across a suite of popular benchmarks.
<img loading="lazy" src="images/model_eval.png#center" alt="model eval"  />

<div style="font-size: 14px; color: grey; text-align: center;">
  (Image Source: Touvron et al. 2023)
</div>

</li>
</ul>
<h2 id="fine-tuning">Fine-Tuning<a hidden class="anchor" aria-hidden="true" href="#fine-tuning">#</a></h2>
<p>Llama 2-Chat is the result of several months of research and iterative applications of alignment techniques, including both instruction tuning and RLHF, requiring significant computational and annotation resources.</p>
<ul>
<li>
<p>Supervised fine-tuning (SFT) with iterative reward modeling and RLHF</p>
</li>
<li>
<p>Annotators have written both the prompt and its answer</p>
<ul>
<li>helpfulness: how well Llama 2-Chat responses fulfill users’ requests and provide requested information</li>
<li>safety: whether Llama 2-Chat’s responses are unsafe</li>
</ul>
</li>
<li>
<p>Find-tuning started with the SFT stage with publicly available instruction tuning data (Chung et al., 2022)</p>
</li>
<li>
<p>To improve alignment, high-quality vendor-based SFT data in the order of tens of thousands is shown to improve the results (Touvron et al. 2023)</p>
</li>
<li>
<p>Data checks are important as different annotation platforms and vendors result in different model performance (Touvron et al. 2023)</p>
</li>
<li>
<p>RLHF is a model training procedure that is applied to a fine-tuned language model to further align model behavior with human preferences and instruction following.</p>
</li>
<li>
<p>Human Preference Data Collection: We ask annotators to first write a prompt, then choose
between two sampled model responses, based on provided criteria. In order to maximize the diversity, the
two responses to a given prompt are sampled from two different model variants, and varying the temperature
hyper-parameter. In addition to giving participants a forced choice, we also ask annotators to label the degree
to which they prefer their chosen response over the alternative: either their choice is significantly better, better,
slightly better, or negligibly better/ unsure. (Touvron et al. 2023)</p>
</li>
<li>
<p>Reward Modeling: The reward model takes a model response and its corresponding prompt (including contexts from previous
turns) as inputs and outputs a scalar score to indicate the quality (e.g., helpfulness and safety) of the model
generation. Leveraging such response scores as rewards, we can optimize Llama 2-Chat during RLHF for
better human preference alignment and improved helpfulness and safety. We train two separate reward
models, one optimized for helpfulness (referred to as Helpfulness RM) and another for safety (Safety RM) to address helpfulness vs. safety trade-off.</p>
</li>
<li>
<p>System Message for Multi-Turn Consistency: In a dialogue setup, the initial RLHF models tended to forget the initial instruction after a few turns of dialogue. To address these limitations, we propose Ghost Attention (GAtt), a very simple method inspired by Context Distillation (Bai et al., 2022b) that hacks the fine-tuning data to help the attention focus in a multi-stage process. GAtt enables dialogue control over multiple turns.
<img loading="lazy" src="images/multi_turn_consistency.png#center" alt="multi-turn consistency"  />

<div style="font-size: 14px; color: grey; text-align: center;">
  (Image Source: Touvron et al. 2023)
</div>

</p>
</li>
<li>
<p>Human evaluation is often considered the gold standard for judging models for natural language generation, including dialogue models. To evaluate the quality of major model versions, we asked human evaluators to rate them on helpfulness and safety (Touvron et al. 2023). Limitations include:</p>
<ul>
<li>Does not cover all real-world usage due to limited number of prompts</li>
<li>Subjective to prompts and instructions</li>
</ul>
</li>
</ul>
<h2 id="safety">Safety<a hidden class="anchor" aria-hidden="true" href="#safety">#</a></h2>
<ul>
<li>
<p>Use safety-specific data annotation and tuning, conduct red-teaming, and employ iterative evaluations.
<img loading="lazy" src="images/safety_evaluation.png#center" alt="safety evaluation"  />

<div style="font-size: 14px; color: grey; text-align: center;">
  (Image Source: Touvron et al. 2023)
</div>

</p>
</li>
<li>
<p>Testing conducted to date has been in English and has not — and could not — cover all scenarios.</p>
</li>
</ul>
<p><img loading="lazy" src="images/training_of_llama2_chat.png#center" alt="training of llama-2-chat"  />

<div style="font-size: 14px; color: grey; text-align: center;">
  (Image Source: Touvron et al. 2023)
</div>

</p>
<ul>
<li>
<p>Safety Metrics</p>
<ul>
<li>Truthfulness</li>
<li>Toxicity</li>
<li>Bias</li>
</ul>
</li>
<li>
<p>Safety Annotation Guidelines</p>
<ul>
<li>illicit and criminal activities (e.g., terrorism, theft, human trafficking)</li>
<li>hateful and harmful activities (e.g., defamation, self-harm, eating disorders discrimination)</li>
<li>unqualified advice (e.g., medical advice, financial advice, legal advice)
We then define best practices for safe and helpful model responses: the model should first address immediate safety concerns if applicable, then address the prompt by explaining the potential risks to the user, and finally provide additional information if possible (Touvron et al. 2023).</li>
</ul>
</li>
<li>
<p>Red Teaming</p>
<ul>
<li>various kinds of proactive risk identification, colloquially called “red teaming,“ based on the term commonly used within computer security (Touvron et al. 2023).</li>
</ul>
</li>
</ul>
<h2 id="reference">Reference<a hidden class="anchor" aria-hidden="true" href="#reference">#</a></h2>
<p>[1] <a href="https://arxiv.org/pdf/2307.09288.pdf">Llama 2: Open Foundation and Fine-Tuned Chat Models (Touvron et al. 2023)
</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://runrunicd.github.io/blog/tags/large-language-model/">large-language-model</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://runrunicd.github.io/blog/post/2023-08-28-llm-fine-tuning/">
    <span class="title">« Prev</span>
    <br>
    <span>Build a Simple Framework for LLM Fine-Tuning on TPU &amp; Applications</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Learning Notes on Large Language Model (Dumping Knowledge for Now) on twitter"
        href="https://twitter.com/intent/tweet/?text=Learning%20Notes%20on%20Large%20Language%20Model%20%28Dumping%20Knowledge%20for%20Now%29&amp;url=https%3a%2f%2frunrunicd.github.io%2fblog%2fpost%2f2023-08-28-llm-reading-notes%2f&amp;hashtags=large-language-model">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Learning Notes on Large Language Model (Dumping Knowledge for Now) on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2frunrunicd.github.io%2fblog%2fpost%2f2023-08-28-llm-reading-notes%2f&amp;title=Learning%20Notes%20on%20Large%20Language%20Model%20%28Dumping%20Knowledge%20for%20Now%29&amp;summary=Learning%20Notes%20on%20Large%20Language%20Model%20%28Dumping%20Knowledge%20for%20Now%29&amp;source=https%3a%2f%2frunrunicd.github.io%2fblog%2fpost%2f2023-08-28-llm-reading-notes%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Learning Notes on Large Language Model (Dumping Knowledge for Now) on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2frunrunicd.github.io%2fblog%2fpost%2f2023-08-28-llm-reading-notes%2f&title=Learning%20Notes%20on%20Large%20Language%20Model%20%28Dumping%20Knowledge%20for%20Now%29">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Learning Notes on Large Language Model (Dumping Knowledge for Now) on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2frunrunicd.github.io%2fblog%2fpost%2f2023-08-28-llm-reading-notes%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Learning Notes on Large Language Model (Dumping Knowledge for Now) on whatsapp"
        href="https://api.whatsapp.com/send?text=Learning%20Notes%20on%20Large%20Language%20Model%20%28Dumping%20Knowledge%20for%20Now%29%20-%20https%3a%2f%2frunrunicd.github.io%2fblog%2fpost%2f2023-08-28-llm-reading-notes%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Learning Notes on Large Language Model (Dumping Knowledge for Now) on telegram"
        href="https://telegram.me/share/url?text=Learning%20Notes%20on%20Large%20Language%20Model%20%28Dumping%20Knowledge%20for%20Now%29&amp;url=https%3a%2f%2frunrunicd.github.io%2fblog%2fpost%2f2023-08-28-llm-reading-notes%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Learning Notes on Large Language Model (Dumping Knowledge for Now) on ycombinator"
        href="https://news.ycombinator.com/submitlink?t=Learning%20Notes%20on%20Large%20Language%20Model%20%28Dumping%20Knowledge%20for%20Now%29&u=https%3a%2f%2frunrunicd.github.io%2fblog%2fpost%2f2023-08-28-llm-reading-notes%2f">
        <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
            xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
            <path
                d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://runrunicd.github.io/blog/">Shel (Run) Zhou&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
