<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>A Simple Framework for LLM Fine-Tuning on TPU &amp; Some Insights | Shel (Run) Zhou&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="Introduction I recently delved into two insightful books: &ldquo;Free Your Mind&rdquo; and &ldquo;The Inner Game of Tennis&rdquo;. Both have illuminated the idea of constructing systems that foster growth and resilience. Consider the journey of scaling a business from scratch. Typically, it starts with a simple MVP crafted by an entrepreneur. As it gains traction in the market, funding and skilled individuals gravitate towards it, refining and expanding the burgeoning product. Similarly, envision establishing a balanced lifestyle anchored by five tenets: health, family, friends, work, and spirituality.">
<meta name="author" content="">
<link rel="canonical" href="https://runrunicd.github.io/blog/post/2023-08-28-llm-fine-tuning/">
<link crossorigin="anonymous" href="/blog/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css" integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U&#43;6hYRq/Ez/nm5vg=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/blog/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://runrunicd.github.io/blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://runrunicd.github.io/blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://runrunicd.github.io/blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://runrunicd.github.io/blog/apple-touch-icon.png">
<link rel="mask-icon" href="https://runrunicd.github.io/blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="A Simple Framework for LLM Fine-Tuning on TPU &amp; Some Insights" />
<meta property="og:description" content="Introduction I recently delved into two insightful books: &ldquo;Free Your Mind&rdquo; and &ldquo;The Inner Game of Tennis&rdquo;. Both have illuminated the idea of constructing systems that foster growth and resilience. Consider the journey of scaling a business from scratch. Typically, it starts with a simple MVP crafted by an entrepreneur. As it gains traction in the market, funding and skilled individuals gravitate towards it, refining and expanding the burgeoning product. Similarly, envision establishing a balanced lifestyle anchored by five tenets: health, family, friends, work, and spirituality." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://runrunicd.github.io/blog/post/2023-08-28-llm-fine-tuning/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-08-28T21:34:17-07:00" />
<meta property="article:modified_time" content="2023-08-28T21:34:17-07:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="A Simple Framework for LLM Fine-Tuning on TPU &amp; Some Insights"/>
<meta name="twitter:description" content="Introduction I recently delved into two insightful books: &ldquo;Free Your Mind&rdquo; and &ldquo;The Inner Game of Tennis&rdquo;. Both have illuminated the idea of constructing systems that foster growth and resilience. Consider the journey of scaling a business from scratch. Typically, it starts with a simple MVP crafted by an entrepreneur. As it gains traction in the market, funding and skilled individuals gravitate towards it, refining and expanding the burgeoning product. Similarly, envision establishing a balanced lifestyle anchored by five tenets: health, family, friends, work, and spirituality."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://runrunicd.github.io/blog/post/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "A Simple Framework for LLM Fine-Tuning on TPU \u0026 Some Insights",
      "item": "https://runrunicd.github.io/blog/post/2023-08-28-llm-fine-tuning/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "A Simple Framework for LLM Fine-Tuning on TPU \u0026 Some Insights",
  "name": "A Simple Framework for LLM Fine-Tuning on TPU \u0026 Some Insights",
  "description": "Introduction I recently delved into two insightful books: \u0026ldquo;Free Your Mind\u0026rdquo; and \u0026ldquo;The Inner Game of Tennis\u0026rdquo;. Both have illuminated the idea of constructing systems that foster growth and resilience. Consider the journey of scaling a business from scratch. Typically, it starts with a simple MVP crafted by an entrepreneur. As it gains traction in the market, funding and skilled individuals gravitate towards it, refining and expanding the burgeoning product. Similarly, envision establishing a balanced lifestyle anchored by five tenets: health, family, friends, work, and spirituality.",
  "keywords": [
    
  ],
  "articleBody": "Introduction I recently delved into two insightful books: “Free Your Mind” and “The Inner Game of Tennis”. Both have illuminated the idea of constructing systems that foster growth and resilience. Consider the journey of scaling a business from scratch. Typically, it starts with a simple MVP crafted by an entrepreneur. As it gains traction in the market, funding and skilled individuals gravitate towards it, refining and expanding the burgeoning product. Similarly, envision establishing a balanced lifestyle anchored by five tenets: health, family, friends, work, and spirituality. Much like a tennis game, it’s about monitoring the system’s progress—shedding the ego, trusting one’s instincts, continually learning, and adapting. This allows the system to organically find its equilibrium and flourish.\nWith that in mind, I’m actively applying this philosophy to my exploration of LLM Fine-Tuning. I will share my code and insights in this post.\nGoals Learn the new way of adapting AI to accomplish a binary classification task. Build a simple framework of LLM fine-tuning. Evaluate AI performance with various conditions or optimization techniques (e.g. training data size). Compare the new way vs. the traditional way of adapting AI. How to fine tune a LLM to accomplish a binary classification task? I’ve had fun to generate content by ChatGPT from OpenAI in response to prompts, but how does one train (or fine-tune) a LLM to accomplish a target prediction task? I’ve tailored a task to predict the sentiments of movie reviews from Rotten Tomatoes, using the OpenLLaMA which is the permissively licensed open source reproduction of Meta AI’s LLaMA large language model.\nA simple framework Setup: The following resources are helpful in accomplishing the task. Installation \u0026 Download: ✅ Set up Google Cloud with GPU/TPU (Note: I have TPU. EasyLM is built for GPU as well)\n✅ Install EasyLM\n✅ Download OpenLLaMA version 3B 2v\n✅ Download Rotten Tomatoes data\nCommon Installation Issues: # Error # https://github.com/huggingface/transformers/issues/19844#issue-1421007669 ImportError: libssl.so.3: cannot open shared object file: No such file or directory # Resolution fix: pip install transformers --force-reinstall # Error sentencepiece\\sentencepiece\\src\\sentencepiece_processor.cc(1102) # Resolution https://github.com/huggingface/transformers/issues/20011 Step 1: Fine tune the pre-trained model (OpenLLaMA 3B V2) on the target task labeled training dataset. # Fine tune Tune a pre-trained model # total_steps: number of tokens divided by seq_length=1024 python3 -m EasyLM.models.llama.llama_train \\ --total_steps=1846 \\ --save_model_freq=1846 \\ --optimizer.adamw_optimizer.lr_warmup_steps=184 \\ --train_dataset.json_dataset.path='/checkpoint/xinleic/tune/EasyLM/data/rotten_tomatoes/output_dataset_train_90.txt' \\ --train_dataset.json_dataset.seq_length=1024 \\ --load_checkpoint='params::/checkpoint/xinleic/tune/EasyLM/my_models/open_llama_3b_v2_easylm/open_llama_3b_v2_easylm' \\ --tokenizer.vocab_file='/checkpoint/xinleic/tune/EasyLM/my_models/open_llama_3b_v2_easylm/tokenizer.model' \\ --logger.output_dir='/checkpoint/xinleic/tune/EasyLM/my_models/open_llama_3b_v2_easylm_tuned_90' \\ --mesh_dim='1,4,2' \\ --load_llama_config='3b' \\ --train_dataset.type='json' \\ --train_dataset.text_processor.fields='text' \\ --optimizer.type='adamw' \\ --optimizer.accumulate_gradient_steps=1 \\ --optimizer.adamw_optimizer.lr=0.002 \\ --optimizer.adamw_optimizer.end_lr=0.002 \\ --optimizer.adamw_optimizer.lr_decay_steps=100000000 \\ --optimizer.adamw_optimizer.weight_decay=0.001 \\ --optimizer.adamw_optimizer.multiply_by_parameter_scale=True \\ --optimizer.adamw_optimizer.bf16_momentum=True Step 2: Serve the tuned model. # Serve fine-tuned model # All Llama models use the same tonkenizer python3 -m EasyLM.models.llama.llama_serve \\ --load_llama_config='3b' \\ --load_checkpoint='params::/checkpoint/xinleic/tune/EasyLM/my_models/open_llama_3b_v2_easylm_tuned/6680d4286a394c999852dcfe33081c44/streaming_params' \\ --tokenizer.vocab_file='/checkpoint/xinleic/tune/EasyLM/my_models/open_llama_3b_v2_easylm/tokenizer.model' Step 3: Evaluate the tuned model on the test dataset. # Evaluate it on the test dataset curl \"http://0.0.0.0:5007/generate\" \\ -H \"Content-Type: application/json\" \\ -X POST --data-binary @/checkpoint/xinleic/tune/EasyLM/data/rotten_tomatoes/eval_output_dataset_test.json | tee /checkpoint/xinleic/tune/EasyLM/data/rotten_tomatoes/eval_output_dataset_test_a4tune.json Evaluation To learn how do variables impact the model performance, I did experimentation on the following variables.\nTraining data size As training data increases, the model performs better on the same test dataset (size = X rows).\nSampling ratio Training data size Accuracy 50% 4265 50% 70% 5971 83.40% 90% 7677 88.74% 100% 8530 87.24% How is it different from the traditional Data Science way of adapting ML model? When building the framework and fine-tuning the LLM, I began to consider how this approach differs from the traditional method of developing a binary classifier in ML. The most significant difference is that the new method is data-centric, while the old one is model-centric.\nFig. 1. The old way of AI/ML development. (Image Source: Snorkel AI) Fig. 2. The new way of AI/ML development. (Image Source: Snorkel AI)\nReferences [1]\nNext Steps The impacts of other parameters in fine-tuning on model performance (e.g. learning rate) Investigate misclassified samples to gather insights about data collection \u0026 quality Exploration of LoRa in excelerating fine-tuning ",
  "wordCount" : "644",
  "inLanguage": "en",
  "datePublished": "2023-08-28T21:34:17-07:00",
  "dateModified": "2023-08-28T21:34:17-07:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://runrunicd.github.io/blog/post/2023-08-28-llm-fine-tuning/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Shel (Run) Zhou's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://runrunicd.github.io/blog/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://runrunicd.github.io/blog/" accesskey="h" title="Shel (Run) Zhou&#39;s Blog (Alt + H)">Shel (Run) Zhou&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      A Simple Framework for LLM Fine-Tuning on TPU &amp; Some Insights
    </h1>
    <div class="post-meta"><span title='2023-08-28 21:34:17 -0700 -0700'>August 28, 2023</span>

</div>
  </header> 
  <div class="post-content"><h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>I recently delved into two insightful books: <a href="https://www.goodreads.com/book/show/121460912-l?from_search=true&amp;from_srp=true&amp;qid=R4FoooIDog&amp;rank=1">&ldquo;Free Your Mind&rdquo;</a> and <a href="https://www.goodreads.com/book/show/905.The_Inner_Game_of_Tennis">&ldquo;The Inner Game of Tennis&rdquo;</a>. Both have illuminated the idea of constructing systems that foster growth and resilience. Consider the journey of scaling a business from scratch. Typically, it starts with a simple MVP crafted by an entrepreneur. As it gains traction in the market, funding and skilled individuals gravitate towards it, refining and expanding the burgeoning product. Similarly, envision establishing a balanced lifestyle anchored by five tenets: health, family, friends, work, and spirituality. Much like a tennis game, it&rsquo;s about monitoring the system&rsquo;s progress—shedding the ego, trusting one&rsquo;s instincts, continually learning, and adapting. This allows the system to organically find its equilibrium and flourish.</p>
<p>With that in mind, I&rsquo;m actively applying this philosophy to my exploration of LLM Fine-Tuning. I will share my code and insights in this post.</p>
<h2 id="goals">Goals<a hidden class="anchor" aria-hidden="true" href="#goals">#</a></h2>
<ul>
<li>Learn the new way of adapting AI to accomplish a binary classification task.</li>
<li>Build a simple framework of LLM fine-tuning.</li>
<li>Evaluate AI performance with various conditions or optimization techniques (e.g. training data size).</li>
<li>Compare the new way vs. the traditional way of adapting AI.</li>
</ul>
<h2 id="how-to-fine-tune-a-llm-to-accomplish-a-binary-classification-task">How to fine tune a LLM to accomplish a binary classification task?<a hidden class="anchor" aria-hidden="true" href="#how-to-fine-tune-a-llm-to-accomplish-a-binary-classification-task">#</a></h2>
<p>I&rsquo;ve had fun to generate content by ChatGPT from OpenAI in response to prompts, but how does one train (or fine-tune) a LLM to accomplish a target prediction task? I&rsquo;ve tailored a task to predict the sentiments of movie reviews from Rotten Tomatoes, using the <a href="https://github.com/openlm-research/open_llama">OpenLLaMA</a> which is the permissively licensed open source reproduction of Meta AI&rsquo;s <a href="https://ai.meta.com/blog/large-language-model-llama-meta-ai/">LLaMA</a> large language model.</p>
<h3 id="a-simple-framework">A simple framework<a hidden class="anchor" aria-hidden="true" href="#a-simple-framework">#</a></h3>
<h4 id="setup-the-following-resources-are-helpful-in-accomplishing-the-task">Setup: The following resources are helpful in accomplishing the task.<a hidden class="anchor" aria-hidden="true" href="#setup-the-following-resources-are-helpful-in-accomplishing-the-task">#</a></h4>
<h5 id="installation--download">Installation &amp; Download:<a hidden class="anchor" aria-hidden="true" href="#installation--download">#</a></h5>
<p>✅ Set up Google Cloud with GPU/TPU (Note: I have TPU. EasyLM is built for GPU as well)<br>
✅ <a href="https://github.com/young-geng/EasyLM">Install EasyLM</a><br>
✅ <a href="https://huggingface.co/openlm-research/open_llama_3b_v2/tree/main?clone=true">Download OpenLLaMA version 3B 2v</a><br>
✅ <a href="https://huggingface.co/datasets/MrbBakh/Rotten_Tomatoes">Download Rotten Tomatoes data</a></p>
<h5 id="common-installation-issues">Common Installation Issues:<a hidden class="anchor" aria-hidden="true" href="#common-installation-issues">#</a></h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Error</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># https://github.com/huggingface/transformers/issues/19844#issue-1421007669</span>
</span></span><span style="display:flex;"><span>ImportError: libssl.so.3: cannot open shared object file: No such file or directory
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Resolution</span>
</span></span><span style="display:flex;"><span>fix: pip install transformers --force-reinstall
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Error</span>
</span></span><span style="display:flex;"><span>sentencepiece<span style="color:#ae81ff">\s</span>entencepiece<span style="color:#ae81ff">\s</span>rc<span style="color:#ae81ff">\s</span>entencepiece_processor.cc<span style="color:#f92672">(</span>1102<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Resolution</span>
</span></span><span style="display:flex;"><span>https://github.com/huggingface/transformers/issues/20011
</span></span></code></pre></div><h4 id="step-1-fine-tune-the-pre-trained-model-openllama-3b-v2-on-the-target-task-labeled-training-dataset">Step 1: Fine tune the pre-trained model (OpenLLaMA 3B V2) on the target task labeled training dataset.<a hidden class="anchor" aria-hidden="true" href="#step-1-fine-tune-the-pre-trained-model-openllama-3b-v2-on-the-target-task-labeled-training-dataset">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Fine tune Tune a pre-trained model</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># total_steps: number of tokens divided by seq_length=1024</span>
</span></span><span style="display:flex;"><span>python3 -m EasyLM.models.llama.llama_train <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --total_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">1846</span>  <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --save_model_freq<span style="color:#f92672">=</span><span style="color:#ae81ff">1846</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --optimizer.adamw_optimizer.lr_warmup_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">184</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --train_dataset.json_dataset.path<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;/checkpoint/xinleic/tune/EasyLM/data/rotten_tomatoes/output_dataset_train_90.txt&#39;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --train_dataset.json_dataset.seq_length<span style="color:#f92672">=</span><span style="color:#ae81ff">1024</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --load_checkpoint<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;params::/checkpoint/xinleic/tune/EasyLM/my_models/open_llama_3b_v2_easylm/open_llama_3b_v2_easylm&#39;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --tokenizer.vocab_file<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;/checkpoint/xinleic/tune/EasyLM/my_models/open_llama_3b_v2_easylm/tokenizer.model&#39;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --logger.output_dir<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;/checkpoint/xinleic/tune/EasyLM/my_models/open_llama_3b_v2_easylm_tuned_90&#39;</span>  <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --mesh_dim<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;1,4,2&#39;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --load_llama_config<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;3b&#39;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --train_dataset.type<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;json&#39;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --train_dataset.text_processor.fields<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;text&#39;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --optimizer.type<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;adamw&#39;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --optimizer.accumulate_gradient_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --optimizer.adamw_optimizer.lr<span style="color:#f92672">=</span>0.002 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --optimizer.adamw_optimizer.end_lr<span style="color:#f92672">=</span>0.002 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --optimizer.adamw_optimizer.lr_decay_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">100000000</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --optimizer.adamw_optimizer.weight_decay<span style="color:#f92672">=</span>0.001 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --optimizer.adamw_optimizer.multiply_by_parameter_scale<span style="color:#f92672">=</span>True <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --optimizer.adamw_optimizer.bf16_momentum<span style="color:#f92672">=</span>True 
</span></span></code></pre></div><h4 id="step-2-serve-the-tuned-model">Step 2: Serve the tuned model.<a hidden class="anchor" aria-hidden="true" href="#step-2-serve-the-tuned-model">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Serve fine-tuned model</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># All Llama models use the same tonkenizer </span>
</span></span><span style="display:flex;"><span>python3 -m EasyLM.models.llama.llama_serve <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --load_llama_config<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;3b&#39;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --load_checkpoint<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;params::/checkpoint/xinleic/tune/EasyLM/my_models/open_llama_3b_v2_easylm_tuned/6680d4286a394c999852dcfe33081c44/streaming_params&#39;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    --tokenizer.vocab_file<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;/checkpoint/xinleic/tune/EasyLM/my_models/open_llama_3b_v2_easylm/tokenizer.model&#39;</span>
</span></span></code></pre></div><h4 id="step-3-evaluate-the-tuned-model-on-the-test-dataset">Step 3: Evaluate the tuned model on the test dataset.<a hidden class="anchor" aria-hidden="true" href="#step-3-evaluate-the-tuned-model-on-the-test-dataset">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Evaluate it on the test dataset</span>
</span></span><span style="display:flex;"><span>curl <span style="color:#e6db74">&#34;http://0.0.0.0:5007/generate&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-H <span style="color:#e6db74">&#34;Content-Type: application/json&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>-X POST --data-binary @/checkpoint/xinleic/tune/EasyLM/data/rotten_tomatoes/eval_output_dataset_test.json | tee /checkpoint/xinleic/tune/EasyLM/data/rotten_tomatoes/eval_output_dataset_test_a4tune.json
</span></span></code></pre></div><h3 id="evaluation">Evaluation<a hidden class="anchor" aria-hidden="true" href="#evaluation">#</a></h3>
<p>To learn how do variables impact the model performance, I did experimentation on the following variables.</p>
<h4 id="training-data-size">Training data size<a hidden class="anchor" aria-hidden="true" href="#training-data-size">#</a></h4>
<p>As training data increases, the model performs better on the same test dataset (size = X rows).</p>
<table>
<thead>
<tr>
<th>Sampling ratio</th>
<th>Training data size</th>
<th>Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td>50%</td>
<td>4265</td>
<td>50%</td>
</tr>
<tr>
<td>70%</td>
<td>5971</td>
<td>83.40%</td>
</tr>
<tr>
<td>90%</td>
<td>7677</td>
<td>88.74%</td>
</tr>
<tr>
<td>100%</td>
<td>8530</td>
<td>87.24%</td>
</tr>
</tbody>
</table>
<h2 id="how-is-it-different-from-the-traditional-data-science-way-of-adapting-ml-model">How is it different from the traditional Data Science way of adapting ML model?<a hidden class="anchor" aria-hidden="true" href="#how-is-it-different-from-the-traditional-data-science-way-of-adapting-ml-model">#</a></h2>
<p>When building the framework and fine-tuning the LLM, I began to consider how this approach differs from the traditional method of developing a binary classifier in ML. The most significant difference is that the new method is data-centric, while the old one is model-centric.</p>
<p><img loading="lazy" src="images/old_way_ai.png" alt="Old Way"  />

<!-- raw HTML omitted --><em>Fig. 1. The old way of AI/ML development. (Image Source: Snorkel AI)</em><!-- raw HTML omitted -->
<img loading="lazy" src="images/new_way_ai.png" alt="New Way"  />

<!-- raw HTML omitted --><em>Fig. 2. The new way of AI/ML development. (Image Source: Snorkel AI)</em><!-- raw HTML omitted --></p>
<h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>
<p>[1]</p>
<h2 id="next-steps">Next Steps<a hidden class="anchor" aria-hidden="true" href="#next-steps">#</a></h2>
<ul>
<li>The impacts of other parameters in fine-tuning on model performance (e.g. learning rate)</li>
<li>Investigate misclassified samples to gather insights about data collection &amp; quality</li>
<li>Exploration of LoRa in excelerating fine-tuning</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://runrunicd.github.io/blog/">Shel (Run) Zhou&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
