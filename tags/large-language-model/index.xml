<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>large-language-model on Shel (Run) Zhou&#39;s Blog</title>
    <link>https://runrunicd.github.io/blog/tags/large-language-model/</link>
    <description>Recent content in large-language-model on Shel (Run) Zhou&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 Nov 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://runrunicd.github.io/blog/tags/large-language-model/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Embeddings Use Cases</title>
      <link>https://runrunicd.github.io/blog/posts/2023-11-14-embeddings/</link>
      <pubDate>Tue, 14 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>https://runrunicd.github.io/blog/posts/2023-11-14-embeddings/</guid>
      <description>Introduction When I first heard about text embeddings, I was perplexed. My tech lead handed me an 800-page Natural Language Processing textbook, but I did not finish reading it. Now, with the capabilities of OpenAI models, it&amp;rsquo;s time to learn and broadly leverage embeddings to accomplish many tasks that were hard be achieved by human labor or simple data analysis, thanks to easy access to these embeddings.
Let&amp;rsquo;s start exploring:</description>
    </item>
    
    <item>
      <title>Learning Notes on Large Language Model (Dumping Knowledge for Now)</title>
      <link>https://runrunicd.github.io/blog/posts/2023-08-28-llm-notes/</link>
      <pubDate>Tue, 01 Aug 2023 13:33:00 -0700</pubDate>
      
      <guid>https://runrunicd.github.io/blog/posts/2023-08-28-llm-notes/</guid>
      <description>Messy &amp;hellip; Introduction to Large Language Model Auto-regressive transformers are pretrained on an extensive corpus of self-supervised data, followed by alignment with human preferences via techniques such as Reinforcement Learning with Human Feedback (RLHF).
Training methodology is simple but is limited to a few players with high computational requirements
Public pretrained LLM
BLOOM (Scao et al., 2022) LLaMa 1 (Touvron et al., 2023) LLaMa 2, LLaMa 2-Chat which is optimized for dialogue use cases Falcon (Penedo et al.</description>
    </item>
    
  </channel>
</rss>
