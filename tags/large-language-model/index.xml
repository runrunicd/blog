<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>large-language-model on Shel (Run) Zhou&#39;s Blog</title>
    <link>https://runrunicd.github.io/blog/tags/large-language-model/</link>
    <description>Recent content in large-language-model on Shel (Run) Zhou&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Aug 2023 13:33:00 -0700</lastBuildDate><atom:link href="https://runrunicd.github.io/blog/tags/large-language-model/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Learning Notes on Large Language Model (Dumping Knowledge for Now)</title>
      <link>https://runrunicd.github.io/blog/post/2023-08-28-llm-reading-notes/</link>
      <pubDate>Tue, 01 Aug 2023 13:33:00 -0700</pubDate>
      
      <guid>https://runrunicd.github.io/blog/post/2023-08-28-llm-reading-notes/</guid>
      <description>Messy &amp;hellip; Introduction to Large Language Model Auto-regressive transformers are pretrained on an extensive corpus of self-supervised data, followed by alignment with human preferences via techniques such as Reinforcement Learning with Human Feedback (RLHF).
Training methodology is simple but is limited to a few players with high computational requirements
Public pretrained LLM
BLOOM (Scao et al., 2022) LLaMa 1 (Touvron et al., 2023) LLaMa 2, LLaMa 2-Chat which is optimized for dialogue use cases Falcon (Penedo et al.</description>
    </item>
    
  </channel>
</rss>
